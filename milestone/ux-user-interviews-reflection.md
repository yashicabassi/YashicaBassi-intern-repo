# ğŸ¤ How to Conduct User Interviews & Usability Testing

## ğŸ¯ Goal
Learn best practices for conducting user interviews and usability tests to gather high-quality insights.

## â“ Why is this important?
User interviews and usability tests help designers understand real user needs. However, if conducted poorly, they can lead to misleading results due to bias, leading questions, or artificial testing conditions.

---

## ğŸ” Research & Learn

### âœ… Best Practices for Conducting User Interviews

- **Define clear objectives**  
  Know what insights you're aiming to gather (e.g., user pain points, task flows, unmet needs).

- **Recruit relevant participants**  
  Select users that represent your target audience or personas.

- **Prepare open-ended, non-leading questions**  
  Example questions:  
  - â€œCan you walk me through how you typically focus during your workday?â€  
  - â€œTell me about a recent time you used an app to manage your productivity.â€

- **Build rapport and set expectations**  
  Help participants feel comfortable. Clarify that their honest feedback is valuable and there's no right or wrong answer.

- **Practice active listening**  
  Let users speak freely and don't interrupt. Probe deeper when needed using follow-up questions.

---

### ğŸ§ª How to Run an Effective Usability Test Without Influencing the User

- **Test the product, not the person**  
  Reassure participants that the test is about evaluating the design, not their abilities.

- **Use task-based, realistic scenarios**  
  Example: â€œImagine you want to start a 25-minute focus session using Focus Bear.â€

- **Encourage the user to think aloud**  
  Ask them to verbalize what theyâ€™re doing and why â€” this reveals their mental model.

- **Avoid leading or suggestive feedback**  
  Donâ€™t guide users or correct their mistakes â€” observe and take notes instead.

- **Observe in silence**  
  Only intervene when the user is completely stuck or needs clarification on the scenario.

---

### ğŸ’¬ What Types of Questions Should UX Designers Ask?

- **Contextual questions**  
  â€œTell me about the last time you felt distracted while working.â€

- **Behavioral questions**  
  â€œHow do you currently manage your focus time or prevent distractions?â€

- **Attitudinal questions**  
  â€œWhat do you look for in a productivity tool or focus app?â€

- **Probing questions**  
  â€œCan you tell me more about what you meant by that?â€

- **Follow-up questions**  
  â€œWhat made that experience frustrating/helpful?â€

âŒ *Avoid these types of questions:*  
- Yes/no questions (e.g., â€œDo you like this?â€)  
- Leading questions (e.g., â€œDonâ€™t you think this is a good feature?â€)

---

### ğŸ“¹ How Recording and Note-Taking Improve Research Accuracy

- **Capture non-verbal cues**  
  Recordings allow you to review tone, pauses, confusion, and expressions that might be missed in real time.

- **Accurate quotes**  
  Transcripts help you include real user quotes in your reports.

- **Structured notes enable pattern discovery**  
  Use note-taking templates or tools like affinity maps or spreadsheets to identify recurring themes and issues.

- **Reduces bias**  
  Reviewing recordings ensures that your conclusions are based on actual user behavior, not assumptions or memory.

---

## ğŸ¤” Reflection Prompts

### â“ If a user struggles with a feature during testing, how do you know if itâ€™s a UX problem or a learning curve issue?

To determine whether it's a UX problem or just a learning curve issue, consider:  
- **Frequency**: If multiple users struggle with the same feature, it points to a UX flaw.  
- **Severity**: If confusion prevents task completion, itâ€™s more than just a learning curve.  
- **Expectations vs. reality**: If the design violates user expectations (e.g., tapping a button that doesn't do what users assumed), itâ€™s a UX issue.  
- **Time taken**: If the user eventually figures it out but takes much longer than expected, it could be a discoverability or affordance issue.

### ğŸ§  How can UX designers ensure they donâ€™t influence user responses during an interview?

- **Use neutral language**: Ask â€œWhat do you think about this screen?â€ instead of â€œDo you like this screen?â€  
- **Avoid reactions**: Donâ€™t nod, smile, or frown in ways that might sway the user.  
- **Refrain from explaining**: Let users navigate independently to reveal genuine usability problems.  
- **Let silence work**: Give users space to think and respond without jumping in to clarify or help.

### ğŸ—‚ï¸ Whatâ€™s the best way to document usability testing results so they are useful for design decisions?

- **Create a usability test summary table** with:  
  - Task descriptions  
  - Success/failure outcomes  
  - Observed issues  
  - Direct quotes  
  - Suggested improvements

- **Highlight patterns**: Group findings by issue type (e.g., navigation, layout, comprehension).  
- **Visuals**: Use screenshots or short clips of the test to illustrate issues.  
- **Prioritize**: Rank issues by severity and impact to help the design team act on what matters most.

---

## ğŸ“ Personal Experience Example

During a university project aimed at developing a mobile study app, I conducted usability testing sessions with five classmates who fit our target audience of college students. I prepared realistic task scenarios such as:

- â€œFind and bookmark a study topic relevant to your next exam.â€  
- â€œSet a reminder for a study session next week.â€

Each participant was observed individually in a quiet room while I encouraged them to think aloud as they navigated the app. I took detailed notes and recorded the sessions (with permission) for later review.

One key insight emerged when a user hesitated to bookmark a topic. They couldnâ€™t find the bookmark icon easily because the iconâ€™s design resembled a generic shape that didnâ€™t align with their mental model. Rather than intervening, I stayed silent and let them try different options, which revealed this discoverability issue clearly.

After testing all participants, I compiled a usability report that included:  
- Task success rates and times  
- Common issues, such as confusion around iconography and navigation labels  
- Direct quotes illustrating usersâ€™ frustration and confusion  
- Suggestions for redesign, such as replacing the bookmark icon with a more intuitive symbol and adding a tooltip on hover

This experience reinforced the importance of observing without interference and documenting real user feedback to prioritize design improvements effectively.

---

